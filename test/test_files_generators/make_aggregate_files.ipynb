{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "import sys, os\n",
    "\n",
    "try:\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../..')))\n",
    "except:\n",
    "    __file__ = os.path.join(os.getcwd(),'make_aggregate_files.ipynb')\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../..')))\n",
    "    \n",
    "import numpy as np\n",
    "import dreem \n",
    "import dreem.util as util\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test files for ```test_set_1.py```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "sample_name = 'test_set_1'\n",
    "number_of_constructs = 2\n",
    "number_of_reads = [10]*number_of_constructs\n",
    "mutations = [[[25]]*4+[[50,75]]*(n-4) for n in number_of_reads]\n",
    "length = 100\n",
    "reads = [[util.create_sequence(length)]*number_of_reads[k] for k in range(number_of_constructs)]\n",
    "insertions = [[[]]*n for n in number_of_reads]\n",
    "deletions = [[[]]*n for n in number_of_reads]\n",
    "constructs = ['construct_{}'.format(i) for i in range(number_of_constructs)]\n",
    "barcode_start = 10\n",
    "barcodes = util.generate_barcodes(8, number_of_constructs, 3)\n",
    "sections_start = [[0,0, 25, 50, 75]]*number_of_constructs\n",
    "sections_end = [[100,25, 50, 75, 99]]*number_of_constructs\n",
    "sections = [['{}_{}'.format(ss, se) for ss,se in zip(sections_start[n], sections_end[n])] for n in range(number_of_constructs)]\n",
    "\n",
    "sample_profile = util.make_sample_profile(constructs, reads, number_of_reads, mutations, insertions, deletions, sections=sections, section_start=sections_start, section_end=sections_end, barcodes=barcodes, barcode_start=barcode_start)\n",
    "test_files_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(__file__)),  '../..', 'test', 'test_files'))\n",
    "\n",
    "inputs = ['bitvector','samples_csv','library']\n",
    "outputs = ['output']\n",
    "util.generate_files(sample_profile, 'aggregate', inputs, outputs, test_files_dir, sample_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def count_bases(positions, l):\n",
    "    out = np.zeros(l, dtype=int)\n",
    "    for p in positions:\n",
    "        if p < l:\n",
    "            out[p] += 1\n",
    "    return out.tolist()\n",
    "\n",
    "def count_mut_indel(positions, l, ss, se):\n",
    "    return [count_bases([a for a in positions[b] if (a>=ss) and (a<se)], se-ss) for b in range(len(positions))]  \n",
    "\n",
    "def count_mut_mod(ref, reads, base):\n",
    "    out = np.zeros(len(ref), dtype=int)\n",
    "    for s in reads:\n",
    "        print(s)\n",
    "        print(ref)\n",
    "        for i in range(len(ref)):\n",
    "            if ref[i] == base and s[i] != base:\n",
    "                out[i] += 1\n",
    "    return out.tolist()\n",
    "\n",
    "\n",
    "def generate_output_files(file, sample_profile, library, samples, clusters = None):\n",
    "    if clusters is None:\n",
    "        library = pd.read_csv(library)\n",
    "        samples = pd.read_csv(samples)\n",
    "        out = samples.to_dict('records')[0]\n",
    "        out['construct'] = {}\n",
    "        for idx, (construct, v) in enumerate(sample_profile.items()):\n",
    "            out['construct'][construct] = {}\n",
    "            out['construct'][construct]['num_reads'] = sample_profile[construct]['number_of_reads']\n",
    "            out['construct'][construct]['num_aligned'] = sample_profile[construct]['number_of_reads']\n",
    "            out['construct'][construct]['barcode'] = v['barcodes']\n",
    "            out['construct'][construct]['barcode_start'] = v['barcode_start']\n",
    "            out['construct'][construct]['some_random_attribute'] = library['some_random_attribute'].values[0]\n",
    "            out['construct'][construct]['sequence'] = v['reference']\n",
    "            for s, ss, se in zip(v['sections'], v['section_start'], v['section_end']):\n",
    "                out['construct'][construct][s] = {}\n",
    "                out['construct'][construct][s]['section_start'] = ss\n",
    "                out['construct'][construct][s]['section_end'] = se\n",
    "                out['construct'][construct][s]['num_of_mutations'] = [len([a for a in v['mutations'][b] if (a>=ss) and (a<se)]) for b in range(len(v['mutations']))]\n",
    "                out['construct'][construct][s]['mut_bases'] =  count_mut_indel(v['mutations'], len(v['reference']), ss, se)\n",
    "                out['construct'][construct][s]['del_bases'] =  count_mut_indel(v['deletions'], len(v['reference']), ss, se)\n",
    "                out['construct'][construct][s]['ins_bases'] =   count_mut_indel(v['insertions'], len(v['reference']), ss, se)\n",
    "                out['construct'][construct][s]['cov_bases'] = [v['number_of_reads']]*(se-ss)\n",
    "                out['construct'][construct][s]['mut_rates'] = np.array( np.array(out['construct'][construct][s]['mut_bases'])/np.array(out['construct'][construct][s]['cov_bases'])).tolist()\n",
    "                for base in ['A', 'C', 'G', 'T']:\n",
    "                    out['construct'][construct][s]['mod_bases_{}'.format(base)] = count_mut_mod(v['reference'][ss:se], [seq[ss:se] for seq in v['reads']], base)\n",
    "    else: \n",
    "        raise NotImplementedError\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(out, f, indent=4)\n",
    "\n",
    "generate_output_files(os.path.join(test_files_dir,'predicted_output','aggregate',sample_name+'.json'), sample_profile, os.path.join(test_files_dir, 'input', 'aggregate', sample_name,'library.csv'),  os.path.join(test_files_dir, 'input', 'aggregate', sample_name,'samples.csv'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "44a9cdcbdccbf05a880e90d2e6fe72470baab4d1b82472d890be0596ed887a6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
